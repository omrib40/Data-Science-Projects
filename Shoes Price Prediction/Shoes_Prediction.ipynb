{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import reduce\n",
    "import random\n",
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('to_predict.csv')\n",
    "train_df = pd.read_csv('all_data.csv')\n",
    "\n",
    "drop = ['color', 'colour', 'lining', 'lining_material',\n",
    "             'main_colour', 'model', 'n_sold', \n",
    "             'platform_height', 'shoe_size', 'shoe_width', \n",
    "             'size', 'vintage', 'year_of_manufacture']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting location column to country only\n",
    "def extract_country(row):\n",
    "    if str(row.location) != 'other':\n",
    "        row.location = row.location.split(\",\")[-1]\n",
    "    return row\n",
    "\n",
    "train_df = train_df.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "test_df = test_df.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "\n",
    "train_df.location = train_df.location.fillna('other')\n",
    "train_df = train_df.apply(extract_country, axis=1)\n",
    "\n",
    "test_df.location = test_df.location.fillna('other')\n",
    "test_df = test_df.apply(extract_country, axis=1)\n",
    "\n",
    "train_df.brand = train_df.brand.fillna('unbranded')\n",
    "test_df.brand = test_df.brand.fillna('unbranded')\n",
    "\n",
    "# chars = ['(',')','[',']','.',':']\n",
    "# for c in chars:\n",
    "#     train_df.replace(c,'',inplace=True)\n",
    "#     test_df.replace(c,'',inplace=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split material, and title column to several columns where each column represent the word found at the i'th place in the string occured on material/title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data frame columns : \n",
      " Index(['id', 'price', 'brand', 'style', 'heel_type', 'heel_height', 'width',\n",
      "       'shoe_width', 'occasion', 'country_region_of_manufacture',\n",
      "       'lining_material', 'upper_material', 'shoe_size', 'toe_shape', 'model',\n",
      "       'year_of_manufacture', 'size', 'colour', 'color', 'main_colour',\n",
      "       'lining', 'sole', 'vintage', 'closure', 'pattern', 'theme', 'fastening',\n",
      "       'platform_height', 'location', 'n_sold', 'n_watchers', 'free_shipping',\n",
      "       'longtime_member', 'same_day_shipping', 'fast_safe_shipping', 'returns',\n",
      "       'feedback', 'condition', 'seller_notes', 'category', 'material_1',\n",
      "       'title_1', 'title_2', 'title_3', 'title_4', 'title_5', 'title_6',\n",
      "       'title_7', 'title_8', 'title_9', 'title_10', 'title_11', 'title_12',\n",
      "       'title_13', 'title_14'],\n",
      "      dtype='object')\n",
      "test data frame columns : \n",
      " Index(['id', 'brand', 'style', 'heel_type', 'heel_height', 'width',\n",
      "       'shoe_width', 'occasion', 'country_region_of_manufacture',\n",
      "       'lining_material', 'upper_material', 'shoe_size', 'toe_shape', 'model',\n",
      "       'year_of_manufacture', 'size', 'colour', 'color', 'main_colour',\n",
      "       'lining', 'sole', 'vintage', 'closure', 'pattern', 'theme', 'fastening',\n",
      "       'platform_height', 'location', 'n_sold', 'n_watchers', 'free_shipping',\n",
      "       'longtime_member', 'same_day_shipping', 'fast_safe_shipping', 'returns',\n",
      "       'feedback', 'condition', 'seller_notes', 'category', 'material_1',\n",
      "       'title_1', 'title_2', 'title_3', 'title_4', 'title_5', 'title_6',\n",
      "       'title_7', 'title_8', 'title_9', 'title_10', 'title_11', 'title_12',\n",
      "       'title_13', 'title_14'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def split_by_and_add_cols(df, col_to_split):\n",
    "    new_df = (df[col_to_split].str.split(' ', expand=True)\n",
    "            .rename(columns=lambda x: f\"{col_to_split}_{x+1}\"))\n",
    "    new_df = new_df.loc[:, new_df.isnull().mean() < .9]\n",
    "    new_df = new_df.fillna(f\"{col_to_split}_other\")\n",
    "    df = pd.merge(left=df, left_index=True,\n",
    "                  right=new_df, right_index=True,\n",
    "                  how='inner')\n",
    "    df.drop(col_to_split,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = split_by_and_add_cols(train_df,'material')\n",
    "train_df = split_by_and_add_cols(train_df,'title')\n",
    "test_df = split_by_and_add_cols(test_df,'material')\n",
    "test_df = split_by_and_add_cols(test_df,'title')\n",
    "print('train data frame columns : \\n', train_df.columns)\n",
    "print('test data frame columns : \\n', test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLTK library to extract the most frequent keywords, and replace in a categorical column.\n",
    "\n",
    "** Eventually I decided not using it as it didn't improved the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces with the first most frequent word\n",
    "def assign_key_words(row, lst, col, nan_name):\n",
    "    first = True\n",
    "    if row[col] != nan_name:\n",
    "        copy = row[col]\n",
    "        for x in lst:\n",
    "            if x[0] in copy and first:\n",
    "                row[col] = x[0]\n",
    "                first = False\n",
    "            elif x[0] in copy:\n",
    "                row[col] += f\" {x[0]}\"\n",
    "    else:\n",
    "        row[col] = nan_name\n",
    "    return row\n",
    "\n",
    "\n",
    "def use_nltk(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(\"other\")\n",
    "        all_d = list(df[col])\n",
    "        all_d_string = \"\\n\".join(all_d)\n",
    "        r = Rake()\n",
    "        r.extract_keywords_from_text(all_d_string)\n",
    "        lst = []\n",
    "        for x in r.get_word_frequency_distribution().most_common():\n",
    "            if x[1] > df.shape[0] * 0.005:\n",
    "                lst.append(x)\n",
    "        df = df.apply(assign_key_words,axis=1,args=(lst, col, \"other\"))\n",
    "    return df\n",
    "\n",
    "#train_df = use_nltk(train_df,['occasion'])\n",
    "#train_df.occasion.unique()\n",
    "#train_df = split_by_and_add_cols(train_df,'occasion')\n",
    "#train_df.columns\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticing for example that for Birkenstock there are > 15 sheos in the data , but only 2 of them has country of manufacture which is Germany, those I filled for every shoe brand it's country_of_manufcature based on other sheos with same brand that there is country_of_manufacture, and if there were several manufacturing area's then I picked the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_country_of_manufacture(df):\n",
    "    df.country_region_of_manufacture = df.country_region_of_manufacture.fillna('unknown')\n",
    "    origin_df = df\n",
    "    df = df[['brand','country_region_of_manufacture']]\n",
    "    df = df[~df['country_region_of_manufacture'].str.contains('^unknown', case=False)]\n",
    "    brand_groups = df.groupby(by='brand')\n",
    "    for grp in brand_groups:\n",
    "        curr_brand = grp[0]\n",
    "        inner = grp[1].groupby(by='country_region_of_manufacture').count().\\\n",
    "        sort_values(by='brand',ascending=False).reset_index()\n",
    "        country = inner.iloc[0]['country_region_of_manufacture']\n",
    "        origin_df.loc[origin_df['brand'] == curr_brand,'country_region_of_manufacture'] = country\n",
    "    return origin_df\n",
    "train_df = handle_country_of_manufacture(train_df)\n",
    "test_df = handle_country_of_manufacture(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "encode_df = pd.concat([train_df.drop('price',axis=1),test_df])\n",
    "encode_vals = encode_df.drop(drop, axis=1).select_dtypes(exclude=np.number).fillna('other').stack().values\n",
    "le.fit(encode_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and fit the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_dropped = train_df.drop(drop, axis=1)\n",
    "df = train_df_dropped.select_dtypes(exclude=np.number).fillna('other')\n",
    "train_df = pd.concat([df.apply(le.transform), train_df_dropped.select_dtypes(include=np.number).fillna(2)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df.drop(['price','id'],axis=1), train_df.price,\n",
    "                                                    test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(n_jobs=-1)\n",
    "parameters = {'nthread':[4], \n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, 0.05, .07], \n",
    "              'max_depth': [4, 5, 6, 7,9,11],\n",
    "              'colsample_bytree': [0.4, 0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 5, 10],\n",
    "              'subsample': [0.7, 1.0],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [400 ,500,800,1000]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_reg,\n",
    "                        parameters,\n",
    "                        cv = 3,\n",
    "                        n_jobs = -1,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "# Save model\n",
    "#xgb_best = pickle.load(open(\"xgb_log_reg.pickle\",'rb'))\n",
    "\n",
    "#print(xgb_best.get_xgb_params())\n",
    "# fit and calcualte rmse\n",
    "#xgb_best.fit(X_train, np.log(y_train))\n",
    "#np.sqrt(sklearn.metrics.mean_squared_error(np.log(y_test),xgb_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking Best parameters and run the model using them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4805672854156389"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Those are the parameters recieved by the gridsearch cv\n",
    "parameters = {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', \n",
    "     'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.7,\n",
    "     'gamma': 0, 'gpu_id': -1, 'interaction_constraints': '', 'learning_rate': 0.03, \n",
    "     'max_delta_step': 0, 'max_depth': 11, 'min_child_weight': 5, \n",
    "     'monotone_constraints': '()', 'n_jobs': -1, 'num_parallel_tree': 5, \n",
    "     'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1.0,\n",
    "     'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None, 'nthread': 4,\n",
    "             'n_estimators': 1000}\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor(**parameters)\n",
    "xgb_reg.fit(X_train, np.log(y_train))\n",
    "np.sqrt(sklearn.metrics.mean_squared_error(np.log(y_test),xgb_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.318223</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.083241</td>\n",
       "      <td>sole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.078643</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040107</td>\n",
       "      <td>country_region_of_manufacture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.037677</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.032413</td>\n",
       "      <td>same_day_shipping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.031364</td>\n",
       "      <td>free_shipping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.028079</td>\n",
       "      <td>fast_safe_shipping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024834</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.022443</td>\n",
       "      <td>returns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.018072</td>\n",
       "      <td>longtime_member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.016008</td>\n",
       "      <td>theme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.015197</td>\n",
       "      <td>title_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015075</td>\n",
       "      <td>style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014870</td>\n",
       "      <td>upper_material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013340</td>\n",
       "      <td>occasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.013008</td>\n",
       "      <td>n_watchers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.012629</td>\n",
       "      <td>title_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012486</td>\n",
       "      <td>toe_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.011604</td>\n",
       "      <td>feedback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009935</td>\n",
       "      <td>fastening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009788</td>\n",
       "      <td>pattern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009646</td>\n",
       "      <td>closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.009363</td>\n",
       "      <td>title_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009259</td>\n",
       "      <td>heel_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008901</td>\n",
       "      <td>heel_height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008847</td>\n",
       "      <td>width</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.008637</td>\n",
       "      <td>material_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.008633</td>\n",
       "      <td>title_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.008414</td>\n",
       "      <td>seller_notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007264</td>\n",
       "      <td>title_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>title_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.007148</td>\n",
       "      <td>title_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.007074</td>\n",
       "      <td>title_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.007005</td>\n",
       "      <td>title_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.006926</td>\n",
       "      <td>title_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.006887</td>\n",
       "      <td>title_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.006826</td>\n",
       "      <td>title_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.006670</td>\n",
       "      <td>title_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.006291</td>\n",
       "      <td>title_11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                              1\n",
       "14  0.318223                       location\n",
       "9   0.083241                           sole\n",
       "15  0.078643                      condition\n",
       "6   0.040107  country_region_of_manufacture\n",
       "17  0.037677                       category\n",
       "36  0.032413              same_day_shipping\n",
       "34  0.031364                  free_shipping\n",
       "37  0.028079             fast_safe_shipping\n",
       "0   0.024834                          brand\n",
       "38  0.022443                        returns\n",
       "35  0.018072                longtime_member\n",
       "12  0.016008                          theme\n",
       "19  0.015197                        title_1\n",
       "1   0.015075                          style\n",
       "7   0.014870                 upper_material\n",
       "5   0.013340                       occasion\n",
       "33  0.013008                     n_watchers\n",
       "20  0.012629                        title_2\n",
       "8   0.012486                      toe_shape\n",
       "39  0.011604                       feedback\n",
       "13  0.009935                      fastening\n",
       "11  0.009788                        pattern\n",
       "10  0.009646                        closure\n",
       "32  0.009363                       title_14\n",
       "2   0.009259                      heel_type\n",
       "3   0.008901                    heel_height\n",
       "4   0.008847                          width\n",
       "18  0.008637                     material_1\n",
       "21  0.008633                        title_3\n",
       "16  0.008414                   seller_notes\n",
       "22  0.007264                        title_4\n",
       "30  0.007173                       title_12\n",
       "24  0.007148                        title_6\n",
       "31  0.007074                       title_13\n",
       "28  0.007005                       title_10\n",
       "26  0.006926                        title_8\n",
       "27  0.006887                        title_9\n",
       "23  0.006826                        title_5\n",
       "25  0.006670                        title_7\n",
       "29  0.006291                       title_11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a glance at the feature importance\n",
    "pd.DataFrame(zip(xgb_reg.feature_importances_,X_train.columns)).sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_dropped = test_df.drop(drop, axis=1)\n",
    "df = test_df_dropped.select_dtypes(exclude=np.number).fillna('other')\n",
    "test_df = pd.concat([df.apply(le.transform), test_df_dropped\n",
    "                    .select_dtypes(include=np.number).fillna(2)],axis=1)\n",
    "# train model\n",
    "xgb_reg = xgboost.XGBRegressor(**parameters)\n",
    "xgb_reg.fit(train_df.drop(['price','id'], axis=1),np.log(train_df['price']))\n",
    "# save test predictions to model01.csv using xgb_best hyper parameters\n",
    "pd.DataFrame(zip(test_df.id, xgb_reg.predict(test_df.drop('id',axis=1))),\n",
    "             columns=['id','price_pred']).to_csv('model05.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find subset of columns that works good with the model\n",
    "def powerset(lst):\n",
    "    return reduce(lambda result, x: result + [subset + [x] for subset in result], lst, [[]])\n",
    "all_subsets = powerset(drop_cols)\n",
    "\n",
    "\n",
    "def try_all():\n",
    "    m = 10\n",
    "    s = []\n",
    "    t_df = pd.read_csv('real_test.csv')\n",
    "    tr_df = pd.read_csv('all_train_data.csv')\n",
    "    \n",
    "    drop_cols = ['closure','color','colour','fastening','lining','lining_material','main_colour','model','n_sold',\n",
    "              'n_watchers','platform_height','seller_notes','shoe_size','shoe_width','size','sole','theme',\n",
    "             'title','vintage','width','year_of_manufacture','style']\n",
    "    \n",
    "    tr_df = tr_df.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "    #train_df = train_df.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "\n",
    "    t_df = t_df.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "    #test_df = test_df.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "\n",
    "    tr_df.location = tr_df.location.fillna('other')\n",
    "    tr_df = tr_df.apply(extract_country, axis=1)\n",
    "\n",
    "    t_df.location = t_df.location.fillna('other')\n",
    "    t_df = t_df.apply(extract_country, axis=1)\n",
    "    \n",
    "    cols = powerset(drop_cols)\n",
    "    arr = random.sample(cols,1000)\n",
    "    for i,drop_cols in enumerate(arr):\n",
    "        test_df = t_df\n",
    "        train_df = tr_df\n",
    "        le = LabelEncoder()\n",
    "        encode_df = pd.concat([train_df.drop('price',axis=1),test_df])\n",
    "        encode_vals = encode_df.drop(drop_cols, axis=1).select_dtypes(exclude=np.number).fillna('other').stack().values\n",
    "        le.fit(encode_vals)\n",
    "        train_df_dropped = train_df.drop(drop_cols, axis=1)\n",
    "        df = train_df_dropped.select_dtypes(exclude=np.number).fillna('other')\n",
    "        train_df = pd.concat([df.apply(le.transform), train_df_dropped.select_dtypes(include=np.number)\n",
    "                              .fillna(2)],axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_df.drop(['price','id'],axis=1), train_df.price,\n",
    "                                                        test_size=0.2, random_state=42)\n",
    "        #xgb_clf = xgboost.XGBRegressor(n_jobs=-1)\n",
    "        #xgb_clf.fit(X_train, np.log(y_train))\n",
    "        xgb_best.fit(X_train, np.log(y_train))\n",
    "        p = np.sqrt(sklearn.metrics.mean_squared_error(np.log(y_test),xgb_best.predict(X_test)))\n",
    "        if p < m:\n",
    "            m = p\n",
    "            s = drop_cols\n",
    "            print(m, s)\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "    return m,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,s = try_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
